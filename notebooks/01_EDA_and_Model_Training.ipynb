{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HEART DISEASE PREDICTION - MLOPS PIPELINE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n✓ COMPLETED COMPONENTS:\")\n",
    "print(\"\\n  DATA MANAGEMENT\")\n",
    "print(\"  ├─ Dataset download and loading\")\n",
    "print(\"  ├─ Data cleaning and preprocessing\")\n",
    "print(\"  ├─ Train-test split with stratification\")\n",
    "print(\"  └─ Feature scaling and normalization\")\n",
    "\n",
    "print(\"\\n  MODEL DEVELOPMENT\")\n",
    "print(\"  ├─ Logistic Regression classifier\")\n",
    "print(\"  ├─ Random Forest classifier\")\n",
    "print(\"  ├─ Hyperparameter tuning (GridSearchCV)\")\n",
    "print(\"  ├─ Cross-validation evaluation\")\n",
    "print(\"  └─ Comprehensive metrics calculation\")\n",
    "\n",
    "print(\"\\n  EXPERIMENT TRACKING\")\n",
    "print(\"  ├─ MLflow integration\")\n",
    "print(\"  ├─ Parameter and metric logging\")\n",
    "print(\"  ├─ Model artifact storage\")\n",
    "print(\"  └─ Experiment comparison\")\n",
    "\n",
    "print(\"\\n  MODEL SERVING\")\n",
    "print(\"  ├─ FastAPI application\")\n",
    "print(\"  ├─ Single & batch prediction endpoints\")\n",
    "print(\"  ├─ Input validation (Pydantic)\")\n",
    "print(\"  └─ Interactive API documentation\")\n",
    "\n",
    "print(\"\\n  TESTING & CI/CD\")\n",
    "print(\"  ├─ Unit tests (preprocessing, models, API)\")\n",
    "print(\"  ├─ Code quality checks (flake8, black)\")\n",
    "print(\"  ├─ Test coverage reporting\")\n",
    "print(\"  └─ GitHub Actions CI/CD pipeline\")\n",
    "\n",
    "print(\"\\n  CONTAINERIZATION & DEPLOYMENT\")\n",
    "print(\"  ├─ Docker container with multi-stage builds\")\n",
    "print(\"  ├─ Docker Compose for local development\")\n",
    "print(\"  ├─ Kubernetes deployment manifests\")\n",
    "print(\"  ├─ Horizontal Pod Autoscaling\")\n",
    "print(\"  └─ Service mesh and ingress configuration\")\n",
    "\n",
    "print(\"\\n  MONITORING & LOGGING\")\n",
    "print(\"  ├─ Structured JSON logging\")\n",
    "print(\"  ├─ Prometheus metrics collection\")\n",
    "print(\"  ├─ Grafana dashboards\")\n",
    "print(\"  └─ Health checks and alerting\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"QUICK START INSTRUCTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. LOCAL DEVELOPMENT:\")\n",
    "print(\"   pip install -r requirements.txt\")\n",
    "print(\"   python scripts/train_model.py\")\n",
    "print(\"   python -m uvicorn src.api.app:app --port 8000\")\n",
    "\n",
    "print(\"\\n2. DOCKER DEPLOYMENT:\")\n",
    "print(\"   docker build -f docker/Dockerfile -t heart-disease-api:latest .\")\n",
    "print(\"   docker-compose -f docker/docker-compose.yml up -d\")\n",
    "\n",
    "print(\"\\n3. KUBERNETES DEPLOYMENT:\")\n",
    "print(\"   kubectl apply -f k8s/deployment.yaml\")\n",
    "print(\"   kubectl apply -f monitoring/prometheus-grafana.yaml\")\n",
    "\n",
    "print(\"\\n4. TESTING:\")\n",
    "print(\"   pytest tests/ -v --cov=src\")\n",
    "\n",
    "print(\"\\n5. MONITORING:\")\n",
    "print(\"   mlflow ui --backend-store-uri file:mlruns\")\n",
    "print(\"   kubectl port-forward svc/grafana 3000:3000\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DOCUMENTATION FILES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  ├─ README.md - Project overview and usage\")\n",
    "print(\"  ├─ INSTALLATION.md - Detailed setup instructions\")\n",
    "print(\"  ├─ DEPLOYMENT.md - Deployment guide\")\n",
    "print(\"  └─ Makefile - Automation commands\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ MLOps PIPELINE SETUP COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Push code to GitHub repository\")\n",
    "print(\"2. Configure GitHub Actions secrets if needed\")\n",
    "print(\"3. Deploy to cloud platform (GKE, EKS, AKS)\")\n",
    "print(\"4. Monitor via Grafana dashboard\")\n",
    "print(\"5. Set up automated retraining pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def02b09",
   "metadata": {},
   "source": [
    "## 14. Project Summary & Next Steps\n",
    "\n",
    "Complete MLOps pipeline overview and deployment instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 13: MONITORING & LOGGING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nLogging features:\")\n",
    "print(\"  - Structured JSON logging\")\n",
    "print(\"  - Request-response logging\")\n",
    "print(\"  - Prediction logging with confidence scores\")\n",
    "print(\"  - Model evaluation metrics logging\")\n",
    "print(\"  - Error and exception logging\")\n",
    "print(\"  - Log file: logs/api.log\")\n",
    "\n",
    "print(\"\\nPrometheus metrics:\")\n",
    "print(\"  - http_requests_total: Total HTTP requests\")\n",
    "print(\"  - http_request_duration_seconds: Request latency\")\n",
    "print(\"  - predictions_total: Total predictions made\")\n",
    "print(\"  - prediction_time_seconds: Prediction latency\")\n",
    "print(\"  - active_requests: Currently active requests\")\n",
    "print(\"  - model_accuracy/precision/recall: Model metrics\")\n",
    "\n",
    "print(\"\\nGrafana dashboards:\")\n",
    "print(\"  - API performance dashboard\")\n",
    "print(\"  - Model metrics dashboard\")\n",
    "print(\"  - Request rate and latency dashboard\")\n",
    "print(\"  - Error rate monitoring\")\n",
    "\n",
    "print(\"\\nDeploy monitoring stack:\")\n",
    "print(\"  kubectl apply -f monitoring/prometheus-grafana.yaml\")\n",
    "\n",
    "print(\"\\nAccess monitoring services:\")\n",
    "print(\"  - Prometheus: http://localhost:9090\")\n",
    "print(\"  - Grafana: http://localhost:3000 (admin/admin)\")\n",
    "\n",
    "print(\"\\nMonitoring setup features:\")\n",
    "print(\"  - Real-time metric collection\")\n",
    "print(\"  - Alerting rules (configurable)\")\n",
    "print(\"  - Custom dashboards\")\n",
    "print(\"  - Performance trending\")\n",
    "print(\"  - Service health monitoring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d8264",
   "metadata": {},
   "source": [
    "## 13. Monitoring & Logging Setup\n",
    "\n",
    "Prometheus metrics collection and Grafana dashboards for production monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 12: KUBERNETES DEPLOYMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nKubernetes manifests:\")\n",
    "print(\"  1. deployment.yaml\")\n",
    "print(\"     - Deployment with 3 replicas\")\n",
    "print(\"     - Rolling update strategy\")\n",
    "print(\"     - Resource limits and requests\")\n",
    "print(\"     - Health checks (liveness & readiness)\")\n",
    "print(\"     - HorizontalPodAutoscaler (2-10 replicas)\")\n",
    "print(\"     - Service (LoadBalancer)\")\n",
    "print(\"\")\n",
    "print(\"  2. ingress.yaml\")\n",
    "print(\"     - Nginx ingress controller\")\n",
    "print(\"     - TLS support\")\n",
    "print(\"     - Host-based routing\")\n",
    "print(\"\")\n",
    "print(\"  3. configmap.yaml\")\n",
    "print(\"     - Application configuration\")\n",
    "print(\"     - Secrets management\")\n",
    "\n",
    "print(\"\\nDeploy to Kubernetes:\")\n",
    "print(\"  kubectl apply -f k8s/deployment.yaml\")\n",
    "\n",
    "print(\"\\nVerify deployment:\")\n",
    "print(\"  kubectl get pods -n heart-disease-prediction\")\n",
    "print(\"  kubectl get svc -n heart-disease-prediction\")\n",
    "\n",
    "print(\"\\nAccess services:\")\n",
    "print(\"  kubectl port-forward svc/heart-disease-api 8000:80 -n heart-disease-prediction\")\n",
    "\n",
    "print(\"\\nAutoscaling triggers:\")\n",
    "print(\"  - CPU utilization > 70%\")\n",
    "print(\"  - Memory utilization > 80%\")\n",
    "\n",
    "print(\"\\nProduction features:\")\n",
    "print(\"  - Load balancing across replicas\")\n",
    "print(\"  - Automatic pod restart on failure\")\n",
    "print(\"  - Graceful shutdown handling\")\n",
    "print(\"  - Resource-aware scheduling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a102e",
   "metadata": {},
   "source": [
    "## 12. Kubernetes Deployment\n",
    "\n",
    "Production-ready Kubernetes configuration with load balancing, autoscaling, and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44401e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 11: DOCKER CONTAINERIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nDockerfile details:\")\n",
    "print(\"  - Base image: python:3.9-slim\")\n",
    "print(\"  - Installs dependencies from requirements.txt\")\n",
    "print(\"  - Exposes port 8000\")\n",
    "print(\"  - Health check configured\")\n",
    "print(\"  - Runs FastAPI application\")\n",
    "\n",
    "print(\"\\nBuild Docker image:\")\n",
    "print(\"  docker build -f docker/Dockerfile -t heart-disease-api:latest .\")\n",
    "\n",
    "print(\"\\nRun Docker container:\")\n",
    "print(\"  docker run -p 8000:8000 heart-disease-api:latest\")\n",
    "\n",
    "print(\"\\nUsing Docker Compose:\")\n",
    "print(\"  docker-compose -f docker/docker-compose.yml up -d\")\n",
    "print(\"  Services: API + MLflow server\")\n",
    "\n",
    "print(\"\\nServices available:\")\n",
    "print(\"  - API: http://localhost:8000\")\n",
    "print(\"  - API Docs: http://localhost:8000/docs\")\n",
    "print(\"  - MLflow: http://localhost:5000\")\n",
    "\n",
    "print(\"\\nContainer features:\")\n",
    "print(\"  - Multi-stage build for smaller image size\")\n",
    "print(\"  - Health checks for monitoring\")\n",
    "print(\"  - Volume mounts for models and logs\")\n",
    "print(\"  - Non-root user execution (security)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f96dd",
   "metadata": {},
   "source": [
    "## 11. Docker Containerization\n",
    "\n",
    "Build and deploy containerized model-serving API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d49933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 10: CI/CD PIPELINE CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nWorkflow file: .github/workflows/mlops_pipeline.yml\")\n",
    "\n",
    "print(\"\\nPipeline stages:\")\n",
    "print(\"  1. Lint and Test\")\n",
    "print(\"     - Python dependency caching\")\n",
    "print(\"     - Code linting (flake8)\")\n",
    "print(\"     - Code formatting check (black)\")\n",
    "print(\"     - Unit tests with coverage\")\n",
    "print(\"     - Coverage report upload\")\n",
    "print(\"\")\n",
    "print(\"  2. Docker Build and Test\")\n",
    "print(\"     - Build Docker image\")\n",
    "print(\"     - Run container health check\")\n",
    "print(\"\")\n",
    "print(\"  3. Model Training\")\n",
    "print(\"     - Run automated model training\")\n",
    "print(\"     - Archive model artifacts\")\n",
    "print(\"     - Archive MLflow runs\")\n",
    "print(\"\")\n",
    "print(\"  4. Workflow Summary\")\n",
    "print(\"     - Generate completion report\")\n",
    "\n",
    "print(\"\\nAutomatically triggered on:\")\n",
    "print(\"  - Push to main/develop branches\")\n",
    "print(\"  - Pull requests to main/develop branches\")\n",
    "\n",
    "print(\"\\nArtifacts generated:\")\n",
    "print(\"  - Test results and coverage reports\")\n",
    "print(\"  - Model artifacts\")\n",
    "print(\"  - MLflow experiment runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912c98f",
   "metadata": {},
   "source": [
    "## 10. CI/CD Pipeline Configuration\n",
    "\n",
    "GitHub Actions workflow for automated testing, building, and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd217e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 9: UNIT TESTING OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nTest files created:\")\n",
    "print(\"  - tests/test_preprocessing.py - Data preprocessing tests\")\n",
    "print(\"  - tests/test_models.py - Model training tests\")\n",
    "print(\"  - tests/test_api.py - API endpoint tests\")\n",
    "print(\"  - tests/conftest.py - Test fixtures and configuration\")\n",
    "\n",
    "print(\"\\nTo run tests:\")\n",
    "print(\"  pytest tests/ -v\")\n",
    "print(\"  pytest tests/ -v --cov=src\")\n",
    "\n",
    "print(\"\\nTest coverage includes:\")\n",
    "print(\"  - Data cleaning and preprocessing\")\n",
    "print(\"  - Missing value handling\")\n",
    "print(\"  - Model training and prediction\")\n",
    "print(\"  - Model evaluation metrics\")\n",
    "print(\"  - Cross-validation\")\n",
    "print(\"  - API endpoint validation\")\n",
    "print(\"  - Input validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d7d23",
   "metadata": {},
   "source": [
    "## 9. Unit Testing\n",
    "\n",
    "Comprehensive testing of data processing, models, and API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 8: API DEVELOPMENT FOR MODEL SERVING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample API test data\n",
    "sample_patient_data = {\n",
    "    'age': 63,\n",
    "    'sex': 1,\n",
    "    'cp': 3,\n",
    "    'trestbps': 145,\n",
    "    'chol': 233,\n",
    "    'fbs': 1,\n",
    "    'restecg': 0,\n",
    "    'thalach': 150,\n",
    "    'exang': 0,\n",
    "    'oldpeak': 2.3,\n",
    "    'slope': 0,\n",
    "    'ca': 0,\n",
    "    'thal': 1\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the sample\n",
    "sample_df = pd.DataFrame([sample_patient_data])\n",
    "print(\"\\nSample input data:\")\n",
    "print(sample_df)\n",
    "\n",
    "# Make prediction\n",
    "prediction = pipeline.predict(sample_df)[0]\n",
    "probability = pipeline.predict_proba(sample_df)[0]\n",
    "\n",
    "print(f\"\\nModel Prediction: {'Disease Present' if prediction == 1 else 'No Disease'}\")\n",
    "print(f\"Confidence scores: No Disease: {probability[0]:.4f}, Disease: {probability[1]:.4f}\")\n",
    "print(f\"Prediction confidence: {max(probability):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813b9a3",
   "metadata": {},
   "source": [
    "## 8. Model Serving - API Development\n",
    "\n",
    "Build a FastAPI application with /predict endpoint for model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1880f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 7: MODEL PACKAGING & SERIALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save models\n",
    "trainer.save_model(lr_best, '../models/artifacts/logistic_regression_model.pkl')\n",
    "trainer.save_model(rf_best, '../models/artifacts/random_forest_model.pkl')\n",
    "\n",
    "# Create and save a prediction wrapper\n",
    "class PredictionPipeline:\n",
    "    def __init__(self, preprocessor_path, model_path):\n",
    "        self.preprocessor = joblib.load(preprocessor_path)\n",
    "        self.model = joblib.load(model_path)\n",
    "    \n",
    "    def predict(self, X_raw):\n",
    "        \"\"\"Make predictions on raw data\"\"\"\n",
    "        X_preprocessed = self.preprocessor.transform(X_raw)\n",
    "        return self.model.predict(X_preprocessed)\n",
    "    \n",
    "    def predict_proba(self, X_raw):\n",
    "        \"\"\"Make probability predictions on raw data\"\"\"\n",
    "        X_preprocessed = self.preprocessor.transform(X_raw)\n",
    "        return self.model.predict_proba(X_preprocessed)\n",
    "\n",
    "# Test the pipeline\n",
    "pipeline = PredictionPipeline(\n",
    "    '../models/artifacts/preprocessor.pkl',\n",
    "    '../models/artifacts/random_forest_model.pkl'\n",
    ")\n",
    "\n",
    "# Make predictions on test set\n",
    "sample_predictions = pipeline.predict(X_test[:5])\n",
    "sample_proba = pipeline.predict_proba(X_test[:5])\n",
    "\n",
    "print(\"\\nSample Predictions (first 5 test samples):\")\n",
    "print(f\"Predictions: {sample_predictions}\")\n",
    "print(f\"Probabilities:\\n{sample_proba}\")\n",
    "\n",
    "# Save pipeline wrapper\n",
    "joblib.dump(pipeline, '../models/artifacts/prediction_pipeline.pkl')\n",
    "print(\"\\nPrediction pipeline saved!\")\n",
    "\n",
    "print(\"\\nModel artifacts saved to: ../models/artifacts/\")\n",
    "print(\"  - logistic_regression_model.pkl\")\n",
    "print(\"  - random_forest_model.pkl\")\n",
    "print(\"  - preprocessor.pkl\")\n",
    "print(\"  - prediction_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29855663",
   "metadata": {},
   "source": [
    "## 7. Model Packaging & Serialization\n",
    "\n",
    "Save models and create reproducible pipelines with preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43466326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 6: EXPERIMENT TRACKING WITH MLFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Set tracking URI\n",
    "mlflow.set_tracking_uri(uri='file:../mlruns')\n",
    "\n",
    "# Create experiment\n",
    "experiment_name = \"heart_disease_prediction\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow experiment: {experiment_name}\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Log Logistic Regression run\n",
    "print(\"\\n--- Logging Logistic Regression Experiment ---\")\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_v1\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        'model_type': 'LogisticRegression',\n",
    "        'C': lr_grid.best_params_['C'],\n",
    "        'solver': lr_grid.best_params_['solver'],\n",
    "        'max_iter': 1000,\n",
    "        'random_state': 42,\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': lr_metrics['accuracy'],\n",
    "        'precision': lr_metrics['precision'],\n",
    "        'recall': lr_metrics['recall'],\n",
    "        'f1_score': lr_metrics['f1'],\n",
    "        'roc_auc': lr_metrics['roc_auc'],\n",
    "    })\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(lr_best, artifact_path=\"model\")\n",
    "    \n",
    "    # Log confusion matrix plot\n",
    "    mlflow.log_artifact('../screenshots/05_confusion_matrix_lr.png')\n",
    "    \n",
    "    print(\"Logistic Regression run logged!\")\n",
    "\n",
    "# Log Random Forest run\n",
    "print(\"\\n--- Logging Random Forest Experiment ---\")\n",
    "with mlflow.start_run(run_name=\"RandomForest_v1\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        'model_type': 'RandomForest',\n",
    "        'n_estimators': rf_grid.best_params_['n_estimators'],\n",
    "        'max_depth': rf_grid.best_params_['max_depth'],\n",
    "        'random_state': 42,\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': rf_metrics['accuracy'],\n",
    "        'precision': rf_metrics['precision'],\n",
    "        'recall': rf_metrics['recall'],\n",
    "        'f1_score': rf_metrics['f1'],\n",
    "        'roc_auc': rf_metrics['roc_auc'],\n",
    "    })\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf_best, artifact_path=\"model\")\n",
    "    \n",
    "    # Log confusion matrix plot\n",
    "    mlflow.log_artifact('../screenshots/06_confusion_matrix_rf.png')\n",
    "    \n",
    "    print(\"Random Forest run logged!\")\n",
    "\n",
    "print(\"\\nMLflow runs logged successfully!\")\n",
    "print(\"To view experiments, run: mlflow ui --backend-store-uri file:../mlruns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d2f8a",
   "metadata": {},
   "source": [
    "## 6. Experiment Tracking with MLflow\n",
    "\n",
    "Log all experiments, parameters, metrics, and artifacts to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3215882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "print(\"\\nGenerating confusion matrix plots...\")\n",
    "trainer.plot_confusion_matrix(lr_metrics['confusion_matrix'], \n",
    "                             \"Logistic Regression\",\n",
    "                             '../screenshots/05_confusion_matrix_lr.png')\n",
    "trainer.plot_confusion_matrix(rf_metrics['confusion_matrix'], \n",
    "                             \"Random Forest\",\n",
    "                             '../screenshots/06_confusion_matrix_rf.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# LR ROC curve\n",
    "y_pred_proba_lr = lr_best.predict_proba(X_test)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "axes[0].plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc_lr:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('Logistic Regression ROC Curve')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# RF ROC curve\n",
    "y_pred_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "axes[1].plot(fpr_rf, tpr_rf, color='green', lw=2, label=f'ROC Curve (AUC = {roc_auc_rf:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Random Forest ROC Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../screenshots/07_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC curves saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison visualization\n",
    "from models.train import compare_models\n",
    "\n",
    "models_dict = {'Logistic Regression': lr_best, 'Random Forest': rf_best}\n",
    "comparison_df = compare_models(models_dict, X_test, y_test)\n",
    "\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('../data/processed/model_comparison.csv', index=False)\n",
    "print(\"\\nComparison saved to model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e57352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation evaluation\n",
    "print(\"\\n--- Cross-Validation Results ---\")\n",
    "\n",
    "cv_lr = trainer.cross_validate_model(lr_best, X_train, y_train, cv_folds=5)\n",
    "cv_rf = trainer.cross_validate_model(rf_best, X_train, y_train, cv_folds=5)\n",
    "\n",
    "print(\"\\nLogistic Regression CV Scores:\")\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    scores = cv_lr[f'test_{metric}']\n",
    "    print(f\"  {metric}: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "\n",
    "print(\"\\nRandom Forest CV Scores:\")\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    scores = cv_rf[f'test_{metric}']\n",
    "    print(f\"  {metric}: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 5: MODEL EVALUATION & COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluate best models on test set\n",
    "lr_best = lr_grid.best_estimator_\n",
    "rf_best = rf_grid.best_estimator_\n",
    "\n",
    "lr_metrics = trainer.evaluate_model(lr_best, X_test, y_test, \"Logistic Regression\")\n",
    "rf_metrics = trainer.evaluate_model(rf_best, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "print(\"\\n--- Logistic Regression Metrics ---\")\n",
    "for key, value in lr_metrics.items():\n",
    "    if key not in ['confusion_matrix', 'classification_report', 'model_name']:\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n--- Random Forest Metrics ---\")\n",
    "for key, value in rf_metrics.items():\n",
    "    if key not in ['confusion_matrix', 'classification_report', 'model_name']:\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca25e7d",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation & Comparison\n",
    "\n",
    "Evaluate models using cross-validation and compare performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca828c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "print(\"\\n--- Hyperparameter Tuning ---\")\n",
    "\n",
    "# Tune Logistic Regression\n",
    "print(\"\\nTuning Logistic Regression...\")\n",
    "lr_params = {'C': [0.1, 1.0, 10.0], 'solver': ['lbfgs', 'liblinear']}\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), \n",
    "                       lr_params, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "print(f\"Best LR params: {lr_grid.best_params_}\")\n",
    "print(f\"Best LR score: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "# Tune Random Forest\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                       rf_params, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(f\"Best RF params: {rf_grid.best_params_}\")\n",
    "print(f\"Best RF score: {rf_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f556428",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 4: MODEL DEVELOPMENT & TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from models.train import ModelTrainer\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ModelTrainer(random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"\\n--- Training Logistic Regression ---\")\n",
    "lr_model = trainer.train_logistic_regression(X_train, y_train, C=1.0, solver='lbfgs')\n",
    "print(\"Logistic Regression trained!\")\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"\\n--- Training Random Forest ---\")\n",
    "rf_model = trainer.train_random_forest(X_train, y_train, n_estimators=100, max_depth=10)\n",
    "print(\"Random Forest trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa97c7f",
   "metadata": {},
   "source": [
    "## 4. Model Development & Training\n",
    "\n",
    "Build and train Logistic Regression and Random Forest classifiers with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"Train target distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "print(f\"Test target distribution:\\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae982775",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: DATA PREPROCESSING & FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from data.preprocessing import DataPreprocessor, split_features_target\n",
    "\n",
    "# Separate features and target\n",
    "X, y = split_features_target(df_clean, target_col='target')\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution: \\n{y.value_counts()}\")\n",
    "\n",
    "# Create and fit preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "\n",
    "print(f\"\\nPreprocessed features shape: {X_preprocessed.shape}\")\n",
    "print(f\"Feature names: {preprocessor.feature_names}\")\n",
    "\n",
    "# Save preprocessor\n",
    "preprocessor.save('../models/artifacts/preprocessor.pkl')\n",
    "print(\"Preprocessor saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218a5ed",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing & Feature Engineering\n",
    "\n",
    "Handle missing values, encode categorical features, and scale numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Box plots for outlier detection\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(df_clean.columns):\n",
    "    if col != 'target':\n",
    "        axes[idx].boxplot(df_clean[col])\n",
    "        axes[idx].set_title(f'Box Plot: {col}', fontsize=10)\n",
    "        axes[idx].set_ylabel(col)\n",
    "        axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../screenshots/04_outlier_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Outlier box plots saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2589fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Class Balance Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count plot\n",
    "target_counts = df_clean['target'].value_counts()\n",
    "axes[0].bar(['No Disease', 'Disease Present'], target_counts.values, color=['green', 'red'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution (Count)')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Percentage plot\n",
    "target_pct = df_clean['target'].value_counts(normalize=True) * 100\n",
    "axes[1].pie(target_pct.values, labels=['No Disease', 'Disease Present'], autopct='%1.1f%%',\n",
    "           colors=['green', 'red'], startangle=90)\n",
    "axes[1].set_title('Class Distribution (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../screenshots/03_class_balance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Class balance analysis saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Correlation Heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix = df_clean.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../screenshots/02_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation heatmap saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c67964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Distributions (Histograms)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(df_clean.columns):\n",
    "    if col != 'target':\n",
    "        axes[idx].hist(df_clean[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=10)\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../screenshots/01_feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature distributions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: EXPLORATORY DATA ANALYSIS (EDA)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clean the data first\n",
    "df_clean = df.dropna()\n",
    "print(f\"Shape after removing missing values: {df_clean.shape}\")\n",
    "\n",
    "# Convert target to binary\n",
    "df_clean['target'] = (df_clean['target'] > 0).astype(int)\n",
    "\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(df_clean['target'].value_counts())\n",
    "print(f\"\\nTarget Distribution (%):\")\n",
    "print(df_clean['target'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f63885",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Professional visualizations including feature distributions, correlations, and class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nData Types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nBasic Statistics:\\n{df.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337362f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.download_data import download_heart_disease_data, load_and_prepare_data\n",
    "\n",
    "# Download dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DATA ACQUISITION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "csv_path = download_heart_disease_data(output_dir='../data/raw')\n",
    "\n",
    "if csv_path:\n",
    "    df = load_and_prepare_data(csv_path)\n",
    "    print(\"\\nDataset successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f5a55",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition & Dataset Exploration\n",
    "\n",
    "Load the Heart Disease UCI Dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c1f5c",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction - MLOps End-to-End Pipeline\n",
    "## Comprehensive ML Model Development with Experiment Tracking and Deployment\n",
    "\n",
    "This notebook covers:\n",
    "1. Data Acquisition & Exploratory Analysis\n",
    "2. Data Preprocessing & Feature Engineering\n",
    "3. Model Development & Training\n",
    "4. Model Evaluation & Comparison\n",
    "5. Experiment Tracking with MLflow\n",
    "6. Model Packaging & Reproducibility\n",
    "7. Model API Development\n",
    "8. Unit Testing\n",
    "9. CI/CD Pipeline Configuration\n",
    "10. Docker Containerization\n",
    "11. Kubernetes Deployment\n",
    "12. Monitoring & Logging"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
